---
title: "Data 621 - Assignment_1"
author: "Salma Elshahawy"
date: "9/9/2020"
output: 
  html_document:
    theme: united
    highlight: tango
    df_print: paged
    code_folding: hide
    toc_depth: 3
---

<<<<<<< HEAD
```{r message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
=======
## Setup

```{r, message=FALSE, warning=FALSE}
>>>>>>> 346dd035e55356969043641315ee5bb9be48b0a8
library(skimr)
library(ggplot2)
library(ggcorrplot)
library(dplyr)
library(tidyr)
library(PerformanceAnalytics)
library(DMwR)
library(caret)
library(kableExtra)
library(DescTools)
library(cowplot)
```

<<<<<<< HEAD

```{r message=FALSE, warning=FALSE}
=======
```{r}
>>>>>>> 346dd035e55356969043641315ee5bb9be48b0a8
data_test <- read.csv("https://raw.githubusercontent.com/salma71/Data_621/master/HW_1/datasets/moneyball-evaluation-data.csv", header = TRUE) %>%select(-INDEX)
data_train <- read.csv("https://raw.githubusercontent.com/salma71/Data_621/master/HW_1/datasets/moneyball-training-data.csv", header = TRUE) %>% select(-INDEX)
```

<<<<<<< HEAD

=======
```{r}
# MI: Preserving original dataset for downstream analysis. Harmonize data_train later. 
data_train_mi <- data_train 
```


>>>>>>> 346dd035e55356969043641315ee5bb9be48b0a8
## Data Exploration

```{r data_dimension_train, message=FALSE, warning=FALSE}
dim(data_train)
```

```{r data_dimension_test, message=FALSE, warning=FALSE}
dim(data_test)
``` 


```{r data_types, message=FALSE, warning=FALSE}
# list types for each attribute
sapply(data_train, class)
```

```{r data_summary_train, message=FALSE, warning=FALSE}
skim(data_train)
```

```{r data_summary_test, message=FALSE, warning=FALSE}
skim(data_test)
```

```{r explore_missing_data_train message=FALSE, warning=FALSE}
data_train %>% 
  gather(variable, value) %>%
  filter(is.na(value)) %>%
  group_by(variable) %>%
  tally() %>%
  mutate(percent = n / nrow(data_train) * 100) %>%
  mutate(percent = paste0(round(percent, ifelse(percent < 10, 1, 0)), "%")) %>%
  arrange(desc(n)) %>%
  rename(`Variable Missing Data` = variable,
         `Number of Records` = n,
         `Share of Total` = percent) %>%
  kable() %>%
  kable_styling()
```

```{r explore_missing_data_test message=FALSE, warning=FALSE}
data_test %>% 
  gather(variable, value) %>%
  filter(is.na(value)) %>%
  group_by(variable) %>%
  tally() %>%
  mutate(percent = n / nrow(data_train) * 100) %>%
  mutate(percent = paste0(round(percent, ifelse(percent < 10, 1, 0)), "%")) %>%
  arrange(desc(n)) %>%
  rename(`Variable Missing Data` = variable,
         `Number of Records` = n,
         `Share of Total` = percent) %>%
  kable() %>%
  kable_styling()
```


### Data Visualization

```{r variables_distribution fig.height=8, fig.width=10, message=FALSE, warning=FALSE}
data_train %>% 
  gather() %>% 
  ggplot( aes(x= value)) + 
  geom_density(fill='pink') + 
  facet_wrap(~key, scales = 'free')
```

Let's take a closer look at the `TEAM_BASERUN_SB` 

```{r explore_Baserunsb fig.height=8, fig.width=10, message=FALSE, warning=FALSE}
data_train %>% 
  ggplot(aes(TEAM_BASERUN_SB)) + 
  geom_histogram(bins = 50, fill = 'pink') +
  geom_vline(aes(xintercept = mean(TEAM_BASERUN_SB, na.rm = T)), col = "red", lty = 2) +
  geom_vline(aes(xintercept = median(TEAM_BASERUN_SB, na.rm = T)), col = "blue", lty = 2) +
  labs(x = element_blank(),
       y = "Count",
       title = "Distribution of Stolen Bases",
       caption = "* Red line is the mean value and blue is the median") + 
  theme_classic()
```

```{r dependent_var_distribution fig.height=4, fig.width=6, message=FALSE, warning=FALSE}
ggplot(data_train, aes(x=TARGET_WINS)) + 
    geom_histogram(aes(y=..density..),binwidth = 3, colour="black", fill="red") +
    geom_density(alpha=.8, fill="pink") + 
  theme_classic()
```

Correlations with Response Variable
Let’s take a look at how the predictors are correlated with the response variable:

```{r correlations_plot fig.height=8, fig.width=10, message=FALSE, warning=FALSE}
q <- cor(data_train)
ggcorrplot(q, type = "upper", outline.color = "white",
           ggtheme = theme_classic,
           colors = c("#6D9EC1", "white", "#E46726"),
           lab = TRUE, show.legend = FALSE, tl.cex = 8, lab_size = 3) 
```

```{r predictors_distribution fig.height=8, fig.width=10, message=FALSE, warning=FALSE}
data_train %>%
  gather(variable, value, -TARGET_WINS) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "pink", color="pink") + 
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins")
```

## Data Preparation

```{r check_na_train_before, message=FALSE, warning=FALSE}
sum(is.na(data_train))/prod(dim(data_train))
```

<<<<<<< HEAD
```{r impute_data_train, message=FALSE, warning=FALSE}
data_train <- data_train %>%
  mutate(TEAM_BATTING_SO = ifelse(TEAM_BATTING_SO == 0, NA, TEAM_BATTING_SO)) %>%
  mutate(TEAM_PITCHING_SO = ifelse(TEAM_PITCHING_SO > 5346, NA, TEAM_PITCHING_SO)) %>%
  select(-TEAM_BATTING_HBP)

set.seed(42)
knn <- data_train %>% knnImputation()
impute_me <- is.na(data_train$TEAM_BATTING_SO)
data_train[impute_me,"TEAM_BATTING_SO"] <- knn[impute_me,"TEAM_BATTING_SO"] 
impute_me <- is.na(data_train$TEAM_BASERUN_SB)
data_train[impute_me,"TEAM_BASERUN_SB"] <- knn[impute_me,"TEAM_BASERUN_SB"] 
impute_me <- is.na(data_train$TEAM_BASERUN_CS)
data_train[impute_me,"TEAM_BASERUN_CS"] <- knn[impute_me,"TEAM_BASERUN_CS"] 
impute_me <- is.na(data_train$TEAM_PITCHING_SO)
data_train[impute_me,"TEAM_PITCHING_SO"] <- knn[impute_me,"TEAM_PITCHING_SO"]
impute_me <- is.na(data_train$TEAM_FIELDING_DP)
data_train[impute_me,"TEAM_FIELDING_DP"] <- knn[impute_me,"TEAM_FIELDING_DP"]
```
=======
## Data Preparation

MI: this passage is just for reference when dealing with leverage point. Can be removed later
Outliers & Leverage Points

In summary, an outlier is a point whose standardized residual falls outside the interval from –2 to 2. Recall that a bad leverage point is a leverage point which is also an outlier. Thus, a bad leverage point is a leverage point whose standar- dized residual falls outside the interval from –2 to 2. On the other hand, a good leverage point is a leverage point whose standardized residual falls inside the interval from –2 to 2.

Recall that the rule for simple linear regression for classifying a point as a leverage point is hii > 4/n . 
>>>>>>> 346dd035e55356969043641315ee5bb9be48b0a8


```{r check_na_after, message=FALSE, warning=FALSE}
sum(is.na(data_train))/prod(dim(data_train))
```
  
Do the same for the `data_test`

```{r check_na_test_before, message=FALSE, warning=FALSE}
sum(is.na(data_test))/prod(dim(data_test))
```

```{r impute_data_test, message=FALSE, warning=FALSE}
data_test <- data_test %>%
  mutate(TEAM_BATTING_SO = ifelse(TEAM_BATTING_SO == 0, NA, TEAM_BATTING_SO)) %>%
  mutate(TEAM_PITCHING_SO = ifelse(TEAM_PITCHING_SO > 5346, NA, TEAM_PITCHING_SO)) %>%
  select(-TEAM_BATTING_HBP)

set.seed(42)
knn <- data_test %>% knnImputation()
impute_me <- is.na(data_test$TEAM_BATTING_SO)
data_test[impute_me,"TEAM_BATTING_SO"] <- knn[impute_me,"TEAM_BATTING_SO"] 
impute_me <- is.na(data_test$TEAM_BASERUN_SB)
data_test[impute_me,"TEAM_BASERUN_SB"] <- knn[impute_me,"TEAM_BASERUN_SB"] 
impute_me <- is.na(data_test$TEAM_BASERUN_CS)
data_test[impute_me,"TEAM_BASERUN_CS"] <- knn[impute_me,"TEAM_BASERUN_CS"] 
impute_me <- is.na(data_test$TEAM_PITCHING_SO)
data_test[impute_me,"TEAM_PITCHING_SO"] <- knn[impute_me,"TEAM_PITCHING_SO"]
impute_me <- is.na(data_test$TEAM_FIELDING_DP)
data_test[impute_me,"TEAM_FIELDING_DP"] <- knn[impute_me,"TEAM_FIELDING_DP"]
```


```{r check_na_test_after, message=FALSE, warning=FALSE}
sum(is.na(data_test))/prod(dim(data_test))
```

<<<<<<< HEAD
### Add feature
=======
#### Feature engineering (continued)

MI: I am creating a new df to not influence the models downstream that may select all features. However, I think all engineered featured should be included in the same dataset, and the individual models under test should select the variables, either from the original set or from the engineered or both. 

Research into baseball statistics suggests the use of the following engineered variables which are composites of variables from the base dataset. These variables, namely "at bats", "batting average", "on base percentage" and "slugging percentage' provide more insight into a team's batting performance by providing variables quantifying the number of opportunities of hitting the ball, the number of times the ball was actually hit, and when hit, how many bases the batter was able to reach. All these variables are representations of a team's ability to score points. (Maybe discuss variables that we expect to benefit the opposing team).

```{r}
data_train_mi <- add_features(data_train)

# Creating "at bats" variable representing every time a batter steps up to bat
data_train_mi <- data_train_mi %>% mutate(TEAM_BATTING_AB = TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BATTING_SO)
# Creating "batting average" variable
data_train_mi <- data_train_mi %>% mutate(TEAM_BATTING_AVG = TEAM_BATTING_H/TEAM_BATTING_AB)
# Creating "on base percentage" representing the proportion of ways to get a base out of total opportunities to hit the ball
data_train_mi <- data_train_mi %>% mutate(TEAM_BATTING_OBP = (TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BATTING_HBP)/(TEAM_BATTING_AB + TEAM_BATTING_BB + TEAM_BATTING_HBP))
# Creating "slugging percentage" which is a weighted sum of hits by number of bases acquired divided by opportunities to hit the ball
data_train_mi <- data_train_mi %>% mutate(TEAM_BATTING_SLG = (TEAM_BATTING_1B + 2*TEAM_BATTING_2B + 3*TEAM_BATTING_3B + 3*TEAM_BATTING_HR)/TEAM_BATTING_AB)
```

Encapsulating the at above into a function. (Use only one of these in final report). Function makes more sense for re-use in prediction

```{r}
add_advanced_bb_features <- function(df) {
  df %>% 
    mutate(TEAM_BATTING_AB = TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BATTING_SO) %>%
    mutate(TEAM_BATTING_AVG = TEAM_BATTING_H/TEAM_BATTING_AB) %>%
    mutate(TEAM_BATTING_OBP = (TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BATTING_HBP)/(TEAM_BATTING_AB + TEAM_BATTING_BB + TEAM_BATTING_HBP)) %>%
    mutate(TEAM_BATTING_SLG = (TEAM_BATTING_1B + 2*TEAM_BATTING_2B + 3*TEAM_BATTING_3B + 3*TEAM_BATTING_HR)/TEAM_BATTING_AB)
}
```

>>>>>>> 346dd035e55356969043641315ee5bb9be48b0a8



## Models Building


```{r}
# simple model
m1 <- lm(TARGET_WINS ~., data = data_train, na.action = na.omit)

summary(m1)
```
needs improvements

```{r}
plot(m1)
```


```{r}
m2 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_HR +TEAM_BATTING_3B +TEAM_BASERUN_CS+TEAM_FIELDING_E+ TEAM_FIELDING_DP, data = data_train)
summary(m2)
```

```{r}
plot(m2)
```

<<<<<<< HEAD
```{r}
full_formula <- "TARGET_WINS ~ TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_SO + TEAM_BASERUN_SB + TEAM_BASERUN_CS + TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_BB + TEAM_PITCHING_SO + TEAM_FIELDING_E + TEAM_FIELDING_DP + TEAM_BATTING_1B + I(TEAM_BATTING_2B^2) + I(TEAM_BATTING_3B^2) + I(TEAM_BATTING_HR^2) + I(TEAM_BATTING_BB^2) + I(TEAM_BATTING_SO^2) + I(TEAM_BASERUN_SB^2) + I(TEAM_BASERUN_CS^2) + I(TEAM_PITCHING_H^2) + I(TEAM_PITCHING_HR^2) + I(TEAM_PITCHING_BB^2) + I(TEAM_PITCHING_SO^2) + I(TEAM_FIELDING_E^2) + I(TEAM_FIELDING_DP^2) + I(TEAM_BATTING_1B^2) + I(TEAM_BATTING_2B^3) + I(TEAM_BATTING_3B^3) + I(TEAM_BATTING_HR^3) + I(TEAM_BATTING_BB^3) + I(TEAM_BATTING_SO^3) + I(TEAM_BASERUN_SB^3) + I(TEAM_BASERUN_CS^3) + I(TEAM_PITCHING_H^3) + I(TEAM_PITCHING_HR^3) + I(TEAM_PITCHING_BB^3) + I(TEAM_PITCHING_SO^3) + I(TEAM_FIELDING_E^3) + I(TEAM_FIELDING_DP^3) + I(TEAM_BATTING_1B^3) + I(TEAM_BATTING_2B^4) + I(TEAM_BATTING_3B^4) + I(TEAM_BATTING_HR^4) + I(TEAM_BATTING_BB^4) + I(TEAM_BATTING_SO^4) + I(TEAM_BASERUN_SB^4) + I(TEAM_BASERUN_CS^4) + I(TEAM_PITCHING_H^4) + I(TEAM_PITCHING_HR^4) + I(TEAM_PITCHING_BB^4) + I(TEAM_PITCHING_SO^4) + I(TEAM_FIELDING_E^4) + I(TEAM_FIELDING_DP^4) + I(TEAM_BATTING_1B^4)"

m3 <- lm(full_formula, data_train)
step_back <- MASS::stepAIC(m3, direction="backward", trace = F)
poly_call <- summary(step_back)$call
step_back <- lm(poly_call[2], data_train)
summary(step_back)
```

```{r}
plot(step_back)
```

## Model selection 

In order to select which model is the “best” we will test it against a test set. We will examine the difference between the predicted and actual values. Since the wins are in whole numbers and the predict function will generate floating point numbers, I will be rounding the results.

=======
### Model 1 - Backwards Elimination


### Model 2 - Engineered Variables

MI: Too many values are removed. These engineered features rely on TEAM_BATTING_HBP in the calculations but this is the variable with the most missing data. Treatment of this variable will affect downstream results.

```{r}
train_mi %>% 
  select(TEAM_BATTING_AB, TEAM_BATTING_AVG, TEAM_BATTING_OBP, TEAM_BATTING_SLG) %>%
  gather() %>% 
  ggplot(aes(x=value)) + 
  geom_density(fill='pink') + 
  facet_wrap(~key, scales = 'free')
```

```{r}
data_train_mi %>%
  gather(variable, value, -c(TARGET_WINS:TEAM_BATTING_1B)) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "pink", color="pink") + 
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins")
```


```{r}
mi_m1 <- lm(TARGET_WINS ~ TEAM_BATTING_AB + TEAM_BATTING_AVG + TEAM_BATTING_OBP + TEAM_BATTING_SLG, data = data_train_mi)
summary(mi_m1)
```

The standardized residual plots show quite a few points outside the -2,2 range, which might justify removing those observations.

Residuals vs Fitted: while the line is not quite horizontal, the constant variance assumption seems met
Normal Q-Q plot: normality assumption is met
Root(Squared Residuals) vs Fitted Values:
Residuals vs Leverage: a few points have standardized residuals outside the (-2,2) ranhe which might justify removing those observations.

```{r}
plot(mi_m1)
```

MI: tyring out predictions on this model

```{r}
data_test_mi <- add_features(data_test)
data_test_mi <- add_advanced_bb_features(data_test_mi)

pred.w.plim <- predict(mi_m1, data_test_mi, interval = "prediction")
pred.w.clim <- predict(mi_m1, data_test_mi, interval = "confidence")
```



### Model 3 - Transformations

## Model Selection

## Prediction
>>>>>>> 346dd035e55356969043641315ee5bb9be48b0a8

