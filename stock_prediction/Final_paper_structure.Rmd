---
title: Predicting the Stock Prices 
author: | 
        | **Dhairav Chhatbar, Mael Illien, Salma Elshahawy**
        | DATA 621, Master of Science in Data Science,
        | City University of New York
output: 
  pdf_document:
    df_print: kable
    toc: no
    fig_caption: yes

nocite: | 
  @wickham_ggplot2_2009, @RCoreTeam, @Chang2015

bibliography: citations.bib
link-citations: yes
---


```{r options_pkgs, echo=F, warning=F, message=F, results=F}
knitr::opts_chunk$set(error = F, message = F, # tidy = T,
                      cache = T, warning = T, 
                      results = 'hide', # suppress code output
                      echo = F,         # suppress code
                      fig.show = 'hide' # suppress plots
                      )
library(readr)
library(skimr)
library(knitcitations)
library(pander)
library(tidyverse)
library(corrplot)
library(quantmod)
library(data.table)
library(car)
library(caret)
```


# Models to try (remove later)

1. Logistic (direction of price movement, up or down)
2. Generalized least squares, auto-regressive model (time series prediction), ARMA, Prophet

# Abstract
Use 250 words or less to summarize your problem, methodology, and major outcomes.

Problem:

Methodology:

Major Outcomes:

# Key Words
Select a few key words (up to five) related to your work.


# Introduction
Describe the background and motivation of your problem.

Background:
- Predicting stock prices or stock movements

Motivation
- Wealth of data available in finance 


# Literature Review
Discuss how other researchers have addressed similar problems, what their achievements are, and what the advantage and drawbacks of each reviewed approach are. Explain how your investigation is similar or different to the state-of-the- art. Please cite the relevant papers where appropriate.


# Methodology
Discuss the key aspects of your problem, data set and regression model(s). Given that you are working on real-world data, explain at a high-level your exploratory data analysis, how you prepared the data for regression modeling, your process for building regression models, and your model selection.

- EDA showing basic time series and indicators
- Data preparation: create new variables? created an up/down indicator
- Models to try


# Experimentation and Results
Describe the specifics of what you did (data exploration, data preparation, model building, model selection, model evaluation, etc.), and what you found out (statistical analyses, interpretation and discussion of the results, etc.).

### Data Description

```{r message=FALSE, warning=FALSE}
dataset <- read_csv('https://raw.githubusercontent.com/salma71/Data_621/master/Project_Proposal/stocks_combined.csv')
tickers <- read_csv('https://raw.githubusercontent.com/salma71/Data_621/master/Project_Proposal/tickers.csv')
skim(dataset)
```

```{r}
head(dataset)
```


### Data Processing

```{r}
dataset$date <- as.Date(dataset$date, format="%m/%d/%Y")
```

### Data Exploration

```{r}
AAPL <- dataset %>% filter(ticker=='AAPL') 
AAPL %>% ggplot(aes(x=date,y=close)) + geom_line()
```





#### Data Transformation for Logistic Model

1. Modify changePercent/change to be our binary target variable
2. Create predictor variables that are not stock dependent like price
- MACD and sig
- Momentum_5 day change % (week)
- Momentum_20 day change % (month)
- RSI
- Volume change

3. Remove observations containing NAs generated by diffential variables (first 26+9 rows as determined by MACD)

```{r}

AAPL_full <- AAPL %>% mutate(macd=MACD(Cl(AAPL), nFast=12, nSlow=26, nSig=9, maType=SMA)[,1], 
                        m5=momentum(AAPL$close, n=5), 
                        m20=momentum(AAPL$close, n=20), 
                        rsi=RSI(AAPL$close, n=14),
                        vol1=ROC(AAPL$volume, n=1),
                        vol5=ROC(AAPL$volume, n=5)) %>%
                        drop_na() %>%
                      select(-c(date,ticker,label, changeOverTime))

head(AAPL_full,10)
```

```{r variables_distribution, fig.height=8, fig.width=10, message=FALSE, warning=FALSE}
AAPL_full %>% 
  keep(is.numeric) %>%
  gather() %>% 
  ggplot(aes(x= value)) + 
  geom_histogram(fill='pink') + 
  facet_wrap(~key, scales = 'free')
```

```{r}
library(corrplot)
corr_dataframe <- AAPL_model1_data %>% mutate_if(is.factor, as.numeric)
corr.d <- cor(corr_dataframe)
corr.d[ lower.tri( corr.d, diag = TRUE ) ] <- NA
corrplot( corr.d, type = "upper", diag = FALSE )
```

```{r}
# Create target variable

AAPL_model1_data <- AAPL_full%>% 
                  mutate(TARGET=if_else(shift(close, n=1, fill=NA, type="lead") > close, 1, 0)) %>%
                  #select(-c(date,ticker,label,open,high,low,close,volume,unadjustedVolume,vwap,change,changeOverTime)) %>%
                  drop_na()
                  
AAPL_model1_data$TARGET <- factor(AAPL_model1_data$TARGET)

head(AAPL_model1_data,10)
```

```{r}
AAPL_model1_data %>% ggplot(aes(x=TARGET)) + geom_histogram(stat="count")
```

### Model 1 (Logistic)

#### M1A Full Model


```{r}
model.full <- glm(TARGET ~ .,
                 data=AAPL_model1_data,
                 family = binomial(link="logit")
                 )
summary(model.full)
```

```{r}
car::vif(model.full)
```

```{r}
glm.probs <- predict(model.full, type="response")
glm.pred <- ifelse(glm.probs > 0.5, 1, 0)
results <- tibble(target=AAPL_model1_data$TARGET, pred=glm.pred)
results <- results %>% mutate(pred.class = as.factor(pred), target.class = as.factor(target))
print(confusionMatrix(results$pred.class,results$target.class, positive = "1"))
```


#### M1B Small Model

The smaller model leads to a nonsensical results where the two variables cancel each other out. Multi-collinearity issue.

```{r}
model.small <- glm(TARGET ~ .-vol5 -high -rsi -open -vol1-changePercent-low-macd-m20-volume-unadjustedVolume-m5-change,
                 data=AAPL_model1_data,
                 family = binomial(link="logit")
                 )
summary(model.small)
```

```{r}
glm.probs <- predict(model.small, type="response")
glm.pred <- ifelse(glm.probs > 0.5, 1, 0)
results <- tibble(target=AAPL_model1_data$TARGET, pred=glm.pred)
results <- results %>% mutate(pred.class = as.factor(pred), target.class = as.factor(target))
print(confusionMatrix(results$pred.class,results$target.class, positive = "1"))
```

#### M1C Multicollinearity Removed

```{r}
m1c_data <- AAPL_model1_data
m1c_data$Close2Open <- m1c_data$open - shift(m1c_data$close, n=1, fill=NA, type="lag")
m1c_data$Open2Open <- m1c_data$open - shift(m1c_data$open, n=1, fill=NA, type="lag")

m1c_data_trimmed <- m1c_data %>% select(-c(open,high,low,vwap,change,macd)) %>% drop_na()
```


This suggests removing open, high and low. Use Close-Close, Close-Open Insteadd

```{r}
m1c.full <- glm(TARGET ~ .,
                 data=m1c_data_trimmed,
                 family = binomial(link="logit")
                 )
summary(m1c.full)
```

```{r}
car::vif(m1c.full)
```

```{r}
glm.probs <- predict(model1c.full, type="response")
glm.pred <- ifelse(glm.probs > 0.5, 1, 0)
results <- tibble(target=m1c_data_trimmed$TARGET, pred=glm.pred)
results <- results %>% mutate(pred.class = as.factor(pred), target.class = as.factor(target))
print(confusionMatrix(results$pred.class,results$target.class, positive = "1"))
```

### Model 2



### Model 3




### Data Imputation

Example for citing @kulkarni_time_2020

### Model Building



### Model Evaluation



### Results


# Discussion and Conclusion
Conclude your findings, limitations, and suggest areas for future work.


\newpage
# Appendix A. Figures


\newpage
# Appendix B. Tables

\newpage
# Appendix C. Code

```{r Code, echo=T, eval=F}
install_load <- function(pkg){
  # Load packages & Install them if needed.
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)
}
```

\newpage
# References


